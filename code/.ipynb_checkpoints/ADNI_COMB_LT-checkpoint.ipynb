{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADNI_COMB_LT\n",
    "##### Xiao Gao, Department of Radiology and Biomedical Imaging, UCSF; Myriam Chaumeil Lab (xiao.gao@ucsf.edu; xiao.gao@berkeley.edu) \n",
    "\n",
    "\n",
    "### Purpose: Reorganizing the puffy `adnicomb` dataset for specific neuroimaging research\n",
    "\n",
    "### Prerequisite: `adnicomb` Pandas DataFrame\n",
    "\n",
    "### Notice: This document is presented by the author(s) as a service to ADNI data users. However, users should be aware that no formal review process has vetted this document and that ADNI cannot guarantee the accuracy or utility of this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.dirname(os.getcwd()) # working from the upper directory of this .ipynd file\n",
    "for root, dirs, files in os.walk(working_dir):\n",
    "    for name in files:\n",
    "        if name=='adnicomb_v1_5.pkl':\n",
    "            adnicomb_dir = root + os.sep + name\n",
    "        if name==\"adnicomb_list.csv\":\n",
    "            comb_list = root + os.sep + name\n",
    "        if name==\"adnicomb_naming_convention.csv\":\n",
    "            nm_conv = root + os.sep + name\n",
    "        \n",
    "comb_df = pd.read_csv(comb_list, usecols=['csv', 'alias', 'date_entry', 'subject_entry', 'subject_type','recruit'])\n",
    "nm_pd = pd.read_csv(nm_conv, usecols=['conv_comb', 'conv_desikan'])         \n",
    "adnicomb = pd.read_pickle(adnicomb_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finding interception of brain regions across different neuroimaging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_interest = ['xv15one','xv30one','xv30two','xv3three','asl','taunpvc', 'tauwpvc','av45','fbb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = ['SV', 'CV', 'SA', 'TA', 'TS', 'HS',\\\n",
    "                'MIN', 'MAX', 'AVG', 'SD', 'CT', 'MD',\\\n",
    "                'SUVR', 'VOLUME']\n",
    "\n",
    "neuro_img_reg = pd.DataFrame()\n",
    "\n",
    "for alias in alias_interest:\n",
    "    temp_columns = pd.Series(adnicomb.filter(regex='^'+alias, axis=1).columns.values)\n",
    "    temp_select = np.zeros_like(temp_columns.values)\n",
    "    for i in range(len(temp_columns)):\n",
    "        for metric in metrics_dict:       \n",
    "            # only brain region entries have specific metric names by the end of column name\n",
    "            if bool(re.search('(?<![A-Z])'+metric+ '(?![A-Z])', temp_columns[i])):\n",
    "                temp_select[i]= 1\n",
    "                temp_string = re.split('_', temp_columns[i])\n",
    "                temp_columns[i]= temp_string[1]\n",
    "                   \n",
    "    neuro_img_reg = pd.concat([ neuro_img_reg, \n",
    "                                pd.DataFrame(temp_columns.loc[temp_select==1].unique(), columns = [alias]) ]\n",
    "                                             ,axis=1)\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_interest = ['xv15one','xv30one','xv30two','xv3three','asl','taunpvc', 'av45']\n",
    "\n",
    "# A for-loop getting intersection of \n",
    "for i in range(len(alias_interest)-1):\n",
    "        col1=alias_interest[i]\n",
    "        col2=alias_interest[i+1]\n",
    "        \n",
    "        if i == 0:\n",
    "            df1 = pd.DataFrame(neuro_img_reg[col1]).rename(columns = {col1:'region'})\n",
    "            df2 = pd.DataFrame(neuro_img_reg[col2]).rename(columns = {col2:'region'})\n",
    "        else:\n",
    "            df1 = inter_region\n",
    "            df2 = pd.DataFrame(neuro_img_reg[col2]).rename(columns = {col2:'region'})\n",
    "\n",
    "        inter_region = pd.merge(df1, df2, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in inter_region.region:\n",
    "         inter_region.loc[inter_region.region==region, 'desikan'] = nm_pd.loc[nm_pd.conv_comb==region,\n",
    "                                                                              'conv_desikan'].values[0]\n",
    "inter_region.sort_values(by=['desikan'], inplace=True)\n",
    "inter_region.reset_index(drop=True, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>desikan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RightVessel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ThirdVentricle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>WMHypoIntensities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>LeftCerebellumWM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>LeftChoroidPlexus</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>CorpusCallosumAnterior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>LeftInferiorLateralVentricle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>LeftLateralVentricle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CorpusCallosumCentral</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CorpusCallosumMidAnterior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CorpusCallosumMidPosterior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LeftVessel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NonWMHypoIntensities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>OpticChiasm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>CorpusCallosumPosterior</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>RightCerebellumWM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>CSF</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RightChoroidPlexus</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>RightInferiorLateralVentricle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>FifthVentricle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>RightLateralVentricle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>FourthVentricle</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            region  desikan\n",
       "86                     RightVessel      NaN\n",
       "87                  ThirdVentricle      NaN\n",
       "88               WMHypoIntensities      NaN\n",
       "89                LeftCerebellumWM      NaN\n",
       "90               LeftChoroidPlexus      NaN\n",
       "91          CorpusCallosumAnterior      NaN\n",
       "92    LeftInferiorLateralVentricle      NaN\n",
       "93            LeftLateralVentricle      NaN\n",
       "94           CorpusCallosumCentral      NaN\n",
       "95       CorpusCallosumMidAnterior      NaN\n",
       "96      CorpusCallosumMidPosterior      NaN\n",
       "97                      LeftVessel      NaN\n",
       "98            NonWMHypoIntensities      NaN\n",
       "99                     OpticChiasm      NaN\n",
       "100        CorpusCallosumPosterior      NaN\n",
       "101              RightCerebellumWM      NaN\n",
       "102                            CSF      NaN\n",
       "103             RightChoroidPlexus      NaN\n",
       "104  RightInferiorLateralVentricle      NaN\n",
       "105                 FifthVentricle      NaN\n",
       "106          RightLateralVentricle      NaN\n",
       "107                FourthVentricle      NaN"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All intersected regions outside of Desikan atlas contain no cortical content\n",
    "inter_region.loc[inter_region.desikan.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 1)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desikan_region = inter_region.loc[inter_region.desikan.notnull()][['region']]\n",
    "desikan_region.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating ADNICOMB_lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entries of interest\n",
    "adnicomb_lt_col=['rid', 'col_prot', 'orig_prot', # merge_RID, merge_COLPROT, merge_ORIGPROT\n",
    " 'exam_date', 'mon_bl', 'age', # merge_EXAMDATE, round(merge_Month_bl/6) * 6, merge_AGE + merge_Years_bl\n",
    " 'dx','dx_bl_fine','dx_bl','dx_end','dx_conv', # merge_DX, merge_DX_bl, merge_DX_bl, merge_DX, (merge_DX & merge_DX_bl)\n",
    " 'gender', 'edu', 'apoe4', # merge_PTGENDER, merge_PTEDUCAT, merge_APOE4\n",
    " 'abeta','tau','ptau', # merge_ABETA, merge_TAU, merge_PTAU\n",
    " 'cdrsb','adas11','adas13','adasq4', # merge_CDRSB, merge_ADAS11, merge_ADAS13, merge_ADASQ4\n",
    " 'mmse','ravlt_immed','ravlt_learn', # merge_MMSE, merge_RAVLT_immediate, merge_RAVLT_learning\n",
    " 'ravlt_forget','ravlt_perc_forget', # merge_RAVLT_forgetting, merge_RAVLT_perc_forgetting\n",
    " 'ldel','digit_score','trailb','faq', # merge_LDELTOTAL, merge_DIGITSCOR, merge_TRABSCOR, merge_FAQ\n",
    " 'moca','ecog_pt_mem','ecog_pt_lang', # merge_MOCA, merge_EcogPtMem, merge_EcogPtLang\n",
    " 'ecog_pt_visspat','ecog_pt_plan', # merge_EcogPtVisspat, merge_EcogPtPlan\n",
    " 'ecog_pt_organ','ecog_pt_divatt','ecog_pt_total', # merge_EcogPtOrgan, merge_EcogPtDivatt, merge_EcogPtTotal\n",
    " 'ecog_sp_mem', 'ecog_sp_lang', 'ecog_sp_visspat', # merge_EcogSPMem, merge_EcogSPLang, merge_EcogSPVisspat\n",
    " 'ecog_sp_plan', 'ecog_sp_organ', # merge_EcogSPPlan, merge_EcogSPOrgan\n",
    " 'ecog_sp_divatt', 'ecog_sp_total', # merge_EcogSPDivatt, merge_EcogSPTotal\n",
    " 'mr_fs','mr_3t','fs_version','fs_icv','fs_cv','fs_atr', # （xv15one or xv30one or xv30two or xv3three）\n",
    " 'tau_pet','tau_subcort_wm','tau_suvr', # taunpvc\n",
    " 'av45_pet','av45_suvr','av45_subcort_wm', # av45\n",
    " 'fbb_pet','fbb_suvr','fbb_subcort_wm', # fbb\n",
    " 'asl','asl_min','asl_max','asl_md','asl_avg','asl_sd', 'asl_ct',  # asl\n",
    " 'msms','msms_version','msms_abeta42','msms_abeta40','msms_abeta38', # (msms1_ or msms2_ + ABETA42, ABETA40, ABETA38)\n",
    " 'nfl_version','nfl'] # (nfl1_ or nfl2_ + PLASMA_NFL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "adni_rid_uniq = adnicomb['merge_RID'].unique()\n",
    "\n",
    "adnicomb_lt = pd.DataFrame(columns = adnicomb_lt_col)\n",
    "adnicomb_lt.rid = adni_rid_uniq\n",
    "\n",
    "for rid in adni_rid_uniq:\n",
    "    temp_df = adnicomb.loc[adnicomb.merge_RID==rid]\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'col_prot'] = temp_df.merge_COLPROT.values[0]\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'orig_prot'] = temp_df.merge_ORIGPROT.values[0]\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'exam_date'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'exam_date'].apply(lambda x: temp_df.merge_EXAMDATE.values)\n",
    "    \n",
    "    temp_mon_bl = np.around(temp_df.merge_Month_bl.values/6).astype(int)*6\n",
    "    temp_mon_bl[temp_df.merge_VISCODE=='m03']=int(3)\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'mon_bl'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'mon_bl'].apply(\n",
    "                        lambda x: temp_mon_bl )\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'age'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'age'].apply(\n",
    "                        lambda x: np.around(temp_df.merge_AGE.values + temp_df.merge_Years_bl.values, decimals=1))\n",
    "    \n",
    "    temp_dx = temp_df.merge_DX.values\n",
    "    temp_dx[temp_dx=='CN']=1\n",
    "    temp_dx[temp_dx=='MCI']=2\n",
    "    temp_dx[temp_dx=='Dementia']=3\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'dx'] = \\\n",
    "                adnicomb_lt.loc[adnicomb_lt.rid==rid, 'dx'].apply(\n",
    "                        lambda x: temp_dx)\n",
    "    \n",
    "    temp_dx_bl_fine = temp_df.merge_DX_bl.values[0]\n",
    "    temp_dx_bl = temp_df.merge_DX_bl.values[0]\n",
    "    if temp_dx_bl_fine == 'CN':\n",
    "        temp_dx_bl_fine = 1\n",
    "        temp_dx_bl=1\n",
    "    elif temp_dx_bl_fine == 'SMC':\n",
    "        temp_dx_bl_fine = 1.5\n",
    "        temp_dx_bl=1\n",
    "    elif temp_dx_bl_fine == 'EMCI':\n",
    "        temp_dx_bl_fine = 2\n",
    "        temp_dx_bl=2\n",
    "    elif temp_dx_bl_fine == 'LMCI':\n",
    "        temp_dx_bl_fine = 2.5\n",
    "        temp_dx_bl=2\n",
    "    elif temp_dx_bl_fine == 'AD':\n",
    "        temp_dx_bl_fine = 3\n",
    "        temp_dx_bl=3\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'dx_bl_fine'] = temp_dx_bl_fine  \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'dx_bl'] = temp_dx_bl\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'dx_end'] = temp_dx[-1:]\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'dx_conv'] = int(temp_dx[-1:]>temp_dx_bl)\n",
    "    \n",
    "    temp_gender = temp_df.merge_PTGENDER.values[0]\n",
    "    if temp_gender == 'Male':\n",
    "        temp_gender = 1\n",
    "    elif temp_gender == 'Female':\n",
    "        temp_gender = 2\n",
    "                \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'gender'] = temp_gender\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'edu'] = temp_df.merge_PTEDUCAT.values[0]\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'apoe4'] = temp_df.merge_APOE4.values[0]\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'abeta'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'abeta'].apply(lambda x: temp_df.merge_ABETA.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'tau'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'tau'].apply(lambda x: temp_df.merge_TAU.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ptau'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ptau'].apply(lambda x: temp_df.merge_PTAU.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'cdrsb'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ptau'].apply(lambda x: temp_df.merge_CDRSB.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'adas11'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'adas11'].apply(lambda x: temp_df.merge_ADAS11.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'adas13'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'adas13'].apply(lambda x: temp_df.merge_ADAS13.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'adasq4'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'adasq4'].apply(lambda x: temp_df.merge_ADASQ4.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'mmse'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'mmse'].apply(lambda x: temp_df.merge_MMSE.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ldel'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ldel'].apply(lambda x: temp_df.merge_LDELTOTAL.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'digit_score'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'digit_score'].apply(lambda x: temp_df.merge_DIGITSCOR.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'trailb'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'trailb'].apply(lambda x: temp_df.merge_TRABSCOR.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'faq'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'faq'].apply(lambda x: temp_df.merge_FAQ.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ravlt_immed'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ravlt_immed'].apply(lambda x: temp_df.merge_RAVLT_immediate.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ravlt_learn'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ravlt_learn'].apply(lambda x: temp_df.merge_RAVLT_learning.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ravlt_forget'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ravlt_forget'].apply(lambda x: temp_df.merge_RAVLT_forgetting.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ravlt_perc_forget'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ravlt_perc_forget'].apply(lambda x: temp_df.merge_RAVLT_perc_forgetting.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'moca'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'moca'].apply(lambda x: temp_df.merge_MOCA.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_mem'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_mem'].apply(lambda x: temp_df.merge_EcogPtMem.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_lang'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_lang'].apply(lambda x: temp_df.merge_EcogPtLang.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_visspat'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_visspat'].apply(lambda x: temp_df.merge_EcogPtVisspat.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_plan'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_plan'].apply(lambda x: temp_df.merge_EcogPtPlan.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_organ'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_organ'].apply(lambda x: temp_df.merge_EcogPtOrgan.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_divatt'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_divatt'].apply(lambda x: temp_df.merge_EcogPtDivatt.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_total'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_pt_total'].apply(lambda x: temp_df.merge_EcogPtTotal.values)\n",
    "    \n",
    "\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_mem'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_mem'].apply(lambda x: temp_df.merge_EcogSPMem.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_lang'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_lang'].apply(lambda x: temp_df.merge_EcogSPLang.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_visspat'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_visspat'].apply(lambda x: temp_df.merge_EcogSPVisspat.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_plan'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_plan'].apply(lambda x: temp_df.merge_EcogSPPlan.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_organ'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_organ'].apply(lambda x: temp_df.merge_EcogSPOrgan.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_divatt'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_divatt'].apply(lambda x: temp_df.merge_EcogSPDivatt.values)\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_total'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'ecog_sp_total'].apply(lambda x: temp_df.merge_EcogSPTotal.values)\n",
    "\n",
    "    \n",
    "    temp_mr_fs = np.full_like(np.empty((temp_df.shape[0])), int(0))\n",
    "    temp_mr_3t = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_fs_version = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_fs_icv = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_fs_cv = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    for region in desikan_region.region:\n",
    "        temp0_pd = temp_df[['xv15one_'+region+'_CV']]\n",
    "        temp1_pd = temp_df[['xv30one_'+region+'_CV']]\n",
    "        temp2_pd = temp_df[['xv30two_'+region+'_CV']]\n",
    "        temp3_pd = temp_df[['xv3three_'+region+'_CV']]\n",
    "        temp_region = pd.concat([temp0_pd, temp1_pd, temp2_pd, temp3_pd], axis=1)\n",
    "        for i in range(temp_region.shape[0]):\n",
    "             for j in range(temp_region.shape[1]):\n",
    "                    if ~np.any(np.isnan(temp_region.values[i][j])):\n",
    "                        temp_fs_cv[i][desikan_region.region.values==region] = np.mean(temp_region.values[i][j])\n",
    "                        if region == 'LeftVentralDC': # only checking the last region\n",
    "                            temp_mr_fs[i]=int(1)                        \n",
    "                            if j==0:\n",
    "                                temp_fs_version[i]= int(43)\n",
    "                                temp_mr_3t[i] = int(0)\n",
    "                                temp_fs_icv[i] = np.mean(temp_df['xv15one_ICV_CV'].values[i])   \n",
    "                            elif j==1:\n",
    "                                temp_fs_version[i]=int(51)\n",
    "                                temp_mr_3t[i] = int(1)\n",
    "                                temp_fs_icv[i] = np.mean(temp_df['xv30one_ICV_CV'].values[i]) \n",
    "                            elif j==2:\n",
    "                                temp_fs_version[i]=int(51)\n",
    "                                temp_mr_3t[i] = int(1)\n",
    "                                temp_fs_icv[i] = np.mean(temp_df['xv30two_ICV_CV'].values[i])\n",
    "                            elif j==3:    \n",
    "                                temp_fs_version[i]=int(60)\n",
    "                                temp_mr_3t[i] = int(1)\n",
    "                                temp_fs_icv[i] = np.mean(temp_df['xv3three_ICV_CV'].values[i])                        \n",
    "                        \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'mr_fs'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'mr_fs'].apply(lambda x: temp_mr_fs.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'mr_3t'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'mr_3t'].apply(lambda x: temp_mr_3t.tolist())\n",
    "\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fs_version'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fs_version'].apply(lambda x: temp_fs_version.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fs_icv'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fs_icv'].apply(lambda x: temp_fs_icv.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fs_cv'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fs_cv'].apply(lambda x: temp_fs_cv.tolist())\n",
    "    \n",
    "    \n",
    "    temp_tau_pet = np.full_like(np.empty((temp_df.shape[0])), int(0))\n",
    "    temp_tau_subcort_wm = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_tau_suvr = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    for region in desikan_region.region:\n",
    "        temp_region = temp_df[['taunpvc_'+region+'_SUVR']]\n",
    "        for i in range(temp_region.shape[0]):\n",
    "                    if ~np.any(np.isnan(temp_region.values[i][0])):\n",
    "                        temp_tau_suvr[i][desikan_region.region.values==region] = np.mean(temp_region.values[i][0])\n",
    "                        if region == 'LeftVentralDC': # only checking the last region\n",
    "                            temp_tau_pet[i]=int(1)                        \n",
    "                            temp_tau_subcort_wm[i] = np.mean(temp_df['taunpvc_ErodedSubcorticalWM_SUVR'].values[i][0])                           \n",
    "                        \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'tau_pet'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'tau_pet'].apply(lambda x: temp_tau_pet.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'tau_subcort_wm'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'tau_subcort_wm'].apply(lambda x: temp_tau_subcort_wm.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'tau_suvr'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'tau_suvr'].apply(lambda x: temp_tau_suvr.tolist())\n",
    " \n",
    "\n",
    "    \n",
    "    temp_av45_pet = np.full_like(np.empty((temp_df.shape[0])), int(0))\n",
    "    temp_av45_subcort_wm = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_av45_suvr = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    for region in desikan_region.region:\n",
    "        temp_region = temp_df[['av45_'+region+'_SUVR']]\n",
    "        for i in range(temp_region.shape[0]):\n",
    "                    if ~np.any(np.isnan(temp_region.values[i][0])):\n",
    "                        temp_av45_suvr[i][desikan_region.region.values==region] = np.mean(temp_region.values[i][0])\n",
    "                        if region == 'LeftVentralDC': # only checking the last region\n",
    "                            temp_av45_pet[i]=int(1)                        \n",
    "                            temp_av45_subcort_wm[i] = np.mean(temp_df['av45_ErodedSubcorticalWM_SUVR'].values[i][0])                           \n",
    "                        \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'av45_pet'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'av45_pet'].apply(lambda x: temp_av45_pet.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'av45_subcort_wm'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'av45_subcort_wm'].apply(lambda x: temp_av45_subcort_wm.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'av45_suvr'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'av45_suvr'].apply(lambda x: temp_av45_suvr.tolist())\n",
    "    \n",
    "\n",
    "    temp_fbb_pet = np.full_like(np.empty((temp_df.shape[0])), int(0))\n",
    "    temp_fbb_subcort_wm = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_fbb_suvr = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    for region in desikan_region.region:\n",
    "        temp_region = temp_df[['fbb_'+region+'_SUVR']]\n",
    "        for i in range(temp_region.shape[0]):\n",
    "                    if ~np.any(np.isnan(temp_region.values[i][0])):\n",
    "                        temp_fbb_suvr[i][desikan_region.region.values==region] = np.mean(temp_region.values[i][0])\n",
    "                        if region == 'LeftVentralDC': # only checking the last region\n",
    "                            temp_fbb_pet[i]=int(1)                        \n",
    "                            temp_fbb_subcort_wm[i] = np.mean(temp_df['fbb_ErodedSubcorticalWM_SUVR'].values[i][0])                           \n",
    "                        \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fbb_pet'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fbb_pet'].apply(lambda x: temp_fbb_pet.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fbb_subcort_wm'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fbb_subcort_wm'].apply(lambda x: temp_fbb_subcort_wm.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fbb_suvr'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'fbb_suvr'].apply(lambda x: temp_fbb_suvr.tolist())\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_asl = np.full_like(np.empty((temp_df.shape[0])), int(0))\n",
    "    temp_asl_min = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    temp_asl_max = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    temp_asl_md = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    temp_asl_avg = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    temp_asl_sd = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)\n",
    "    temp_asl_ct = np.full_like(np.empty((temp_df.shape[0], desikan_region.shape[0])), np.nan)  \n",
    "    for region in desikan_region.region:\n",
    "        temp_region_min = temp_df[['asl_'+region+'_MIN']]\n",
    "        temp_region_max = temp_df[['asl_'+region+'_MAX']]\n",
    "        temp_region_md = temp_df[['asl_'+region+'_MD']]\n",
    "        temp_region_avg = temp_df[['asl_'+region+'_AVG']]\n",
    "        temp_region_sd = temp_df[['asl_'+region+'_SD']]\n",
    "        temp_region_ct = temp_df[['asl_'+region+'_CT']]\n",
    "        for i in range(temp_region_min.shape[0]):\n",
    "                    if ~np.any(np.isnan(temp_region_min.values[i][0])):\n",
    "                        temp_asl_min[i][desikan_region.region.values==region] = np.mean(temp_region_min.values[i][0])\n",
    "                        temp_asl_max[i][desikan_region.region.values==region] = np.mean(temp_region_max.values[i][0])\n",
    "                        temp_asl_md[i][desikan_region.region.values==region] = np.mean(temp_region_md.values[i][0])\n",
    "                        temp_asl_avg[i][desikan_region.region.values==region] = np.mean(temp_region_avg.values[i][0])\n",
    "                        temp_asl_sd[i][desikan_region.region.values==region] = np.mean(temp_region_sd.values[i][0])\n",
    "                        temp_asl_ct[i][desikan_region.region.values==region] = np.mean(temp_region_ct.values[i][0])\n",
    "                        if region == 'LeftVentralDC': # only checking the last region\n",
    "                            temp_asl[i]=int(1)                                                  \n",
    "                        \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl'].apply(lambda x: temp_asl.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_min'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_min'].apply(lambda x: temp_asl_min.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_max'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_max'].apply(lambda x: temp_asl_max.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_md'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_md'].apply(lambda x: temp_asl_md.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_avg'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_avg'].apply(lambda x: temp_asl_avg.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_sd'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_sd'].apply(lambda x: temp_asl_sd.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_ct'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'asl_ct'].apply(lambda x: temp_asl_ct.tolist())\n",
    "    \n",
    "      \n",
    "    \n",
    "    temp_msms = np.full_like(np.empty((temp_df.shape[0])), 0)\n",
    "    temp_msms_version = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_msms_abeta42 = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_msms_abeta40 = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_msms_abeta38 = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    for region in ['ABETA42','ABETA40','ABETA38']:\n",
    "        temp0_pd = temp_df[['msms1_'+region]]\n",
    "        temp1_pd = temp_df[['msms2_'+region]]\n",
    "        temp_region = pd.concat([temp0_pd, temp1_pd], axis=1)\n",
    "        for i in range(temp_region.shape[0]):\n",
    "             for j in range(temp_region.shape[1]):\n",
    "                    if ~np.any(np.isnan(temp_region.values[i][j])):                       \n",
    "                        if region == 'ABETA38': \n",
    "                            temp_msms_abeta38[i]=np.mean(temp_region.values[i][j])\n",
    "                            temp_msms[i]=1                        \n",
    "                            if j==0:\n",
    "                                temp_msms_version[i]=int(1)  \n",
    "                            elif j==1:\n",
    "                                temp_msms_version[i]=int(2)\n",
    "                        elif region == 'ABETA40': \n",
    "                            temp_msms_abeta40[i]=np.mean(temp_region.values[i][j])\n",
    "                            temp_msms[i]=1 \n",
    "                        elif region == 'ABETA42': \n",
    "                            temp_msms_abeta42[i]=np.mean(temp_region.values[i][j])\n",
    "                            temp_msms[i]=1    \n",
    "                                    \n",
    "     \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms'].apply(lambda x: temp_msms.tolist())\n",
    "\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms_version'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms_version'].apply(lambda x: temp_msms_version.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms_abeta42'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms_abeta42'].apply(lambda x: temp_msms_abeta42.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms_abeta40'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms_abeta40'].apply(lambda x: temp_msms_abeta40.tolist())\n",
    "    \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms_abeta38'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'msms_abeta38'].apply(lambda x: temp_msms_abeta38.tolist())\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    temp_nfl_version = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    temp_nfl = np.full_like(np.empty((temp_df.shape[0])), np.nan)\n",
    "    for region in ['PLASMA_NFL']:\n",
    "        temp0_pd = temp_df[['nfl1_'+region]]\n",
    "        temp1_pd = temp_df[['nfl2_'+region]]\n",
    "        temp_region = pd.concat([temp0_pd, temp1_pd], axis=1)\n",
    "        for i in range(temp_region.shape[0]):\n",
    "             for j in range(temp_region.shape[1]):\n",
    "                    if ~np.any(np.isnan(temp_region.values[i][j])):                       \n",
    "                        temp_nfl[i]=np.mean(temp_region.values[i][j])                      \n",
    "                        if j==0:\n",
    "                            temp_nfl_version[i]=int(1)  \n",
    "                        elif j==1:\n",
    "                            temp_nfl_version[i]=int(2)                                    \n",
    "     \n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'nfl'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'nfl'].apply(lambda x: temp_nfl.tolist())\n",
    "\n",
    "    adnicomb_lt.loc[adnicomb_lt.rid==rid, 'nfl_version'] = \\\n",
    "            adnicomb_lt.loc[adnicomb_lt.rid==rid, 'nfl_version'].apply(lambda x: temp_nfl_version.tolist())\n",
    "\n",
    "    #'abeta42','abeta40','abeta38', # (msms1_ or msms2_ + ABETA42, ABETA40, ABETA38)\n",
    " #'nfl'] # (nfl1_ or nfl2_ + PLASMA_NFL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adnicomb_lt.to_pickle(working_dir+'/adnicomb_lt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adnicomb_lt= pd.read_pickle(working_dir+'/adnicomb_lt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_RID</th>\n",
       "      <th>merge_EXAMDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>112</td>\n",
       "      <td>2006-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>112</td>\n",
       "      <td>2006-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>112</td>\n",
       "      <td>2007-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>112</td>\n",
       "      <td>2007-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>112</td>\n",
       "      <td>2008-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>112</td>\n",
       "      <td>2008-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>112</td>\n",
       "      <td>2009-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>112</td>\n",
       "      <td>2009-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>112</td>\n",
       "      <td>2010-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>112</td>\n",
       "      <td>2010-08-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>112</td>\n",
       "      <td>2011-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>112</td>\n",
       "      <td>2011-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>112</td>\n",
       "      <td>2012-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>112</td>\n",
       "      <td>2012-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>112</td>\n",
       "      <td>2013-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>112</td>\n",
       "      <td>2013-07-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>112</td>\n",
       "      <td>2014-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>112</td>\n",
       "      <td>2015-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>112</td>\n",
       "      <td>2016-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>112</td>\n",
       "      <td>2017-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>112</td>\n",
       "      <td>2018-07-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     merge_RID merge_EXAMDATE\n",
       "688        112     2006-02-01\n",
       "689        112     2006-07-27\n",
       "690        112     2007-02-07\n",
       "691        112     2007-07-30\n",
       "692        112     2008-01-29\n",
       "693        112     2008-07-25\n",
       "694        112     2009-01-23\n",
       "695        112     2009-08-07\n",
       "696        112     2010-01-28\n",
       "697        112     2010-08-27\n",
       "698        112     2011-01-21\n",
       "699        112     2011-08-15\n",
       "700        112     2012-01-18\n",
       "701        112     2012-07-25\n",
       "702        112     2013-01-23\n",
       "703        112     2013-07-23\n",
       "704        112     2014-01-23\n",
       "705        112     2015-05-19\n",
       "706        112     2016-02-05\n",
       "707        112     2017-07-07\n",
       "708        112     2018-07-18"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adnicomb.loc[adnicomb.merge_RID==112,['merge_RID','merge_EXAMDATE']].join(adnicomb.loc[adnicomb.merge_RID==112].filter(regex='RightMiddleTemporal_vol$', axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
